# 第 4 章 · 从零实现一个最小 3DGS 系统

## 1. 开篇：解构黑盒

在 3D Gaussian Splatting (3DGS) 官方源码中，最令人望而生畏的是数百行的 CUDA Kernel 和复杂的并行策略（如 Radix Sort, Tile-based Rasterization）。很多初学者因此认为 3DGS 是“黑魔法”。

但如果我们剥离掉为了达到 100+ FPS 而做的工程优化，3DGS 的核心逻辑极其优雅且简单。它本质上是一个**可微的光栅化器（Differentiable Rasterizer）**。

**本章目标**：
在不触碰 CUDA C++ 的前提下，仅利用 PyTorch 的张量运算逻辑，构建一个“最小可行”的 3DGS 渲染与训练闭环。我们将像拆解钟表一样把每一个齿轮（数学公式）和弹簧（数据流）摆在桌面上。

**你将学到**：
1.  **高斯的生命周期**：从初始化到投影、着色、分裂、消亡。
2.  **前向传播的数学链条**：如何把一个 3D 椭球变成屏幕上的像素颜色。
3.  **反向传播的梯度流**：像素误差如何穿过透明度混合公式，精确修正椭球的形状。
4.  **拓扑结构的可变性**：为什么“克隆”和“分裂”是 3DGS 效果超越 NeRF 的关键。

---

## 2. 数据结构：场景的原子表达

在 NeRF 中，场景被隐式存储在 MLP 的权重里；而在 3DGS 中，场景是**显式**的。我们需要维护一张巨大的“高斯列表”。

### 2.1 高斯点云模型 (The Gaussian Model)

假设场景中有 $N$ 个高斯点（初始可能为 SfM 的稀疏点云，如 100k 个），我们需要维护以下可优化张量。请注意每个属性的**激活函数**设计，这对训练稳定性至关重要。

| 属性 | 符号 | 维度 | 物理含义 | 存储形式与激活策略 |
| :--- | :--- | :--- | :--- | :--- |
| **位置** | $\mu$ | $(N, 3)$ | 3D 中心坐标 | 直接存储。学习率需根据场景尺度调整。 |
| **旋转** | $q$ | $(N, 4)$ | 3D 姿态 | 存储为四元数 $(w, x, y, z)$。使用前需归一化 $\frac{q}{\|q\|}$ 以保证为单位四元数。 |
| **尺度** | $s$ | $(N, 3)$ | 椭球三轴长度 | 存储为 $\ln(s)$。使用时取 $\exp(\cdot)$。**原因**：保证尺度非负，且梯度在不同量级下更均衡。 |
| **不透明度** | $\alpha$ | $(N, 1)$ | 实体密度 | 存储为 logit。使用时取 $\text{Sigmoid}(\cdot)$ 映射到 $[0, 1)$。 |
| **球谐系数** | $c$ | $(N, k, 3)$ | 视角相关颜色 | 分为 DC（0阶，基础色）和 Rest（高阶，视线相关）。通常 $k=16$ (3阶 SH)。 |

> **关键设计 (Rule-of-Thumb)**：不要直接优化协方差矩阵 $\Sigma$。尽管 $\Sigma$ 定义了高斯形状，但它必须保持**半正定**。通过优化 $q$ 和 $s$ 并通过公式 $\Sigma = R(q)S(s)S(s)^T R(q)^T$ 合成，我们在数学上强制保证了 $\Sigma$ 的合法性。

### 2.2 相机模型

每个训练迭代需要从一个视点渲染。你需要准备：
*   **外参 (Extrinsics)**：世界到相机变换矩阵 $W \in \mathbb{R}^{4 \times 4}$ (World-to-Camera)。
*   **内参 (Intrinsics)**：焦距 $f_x, f_y$ 和光心 $c_x, c_y$，或者投影矩阵 $P$。
*   **图像尺寸**：$H, W$。

---

## 3. 前向渲染管线 (Forward Pass) 深度拆解

这是本章的核心。渲染过程是将 3D 高斯“拍扁”到 2D 屏幕并融合颜色的过程。

### 步骤 1: 协方差构建 (Covariance Construction)

**输入**：$q, s$
**输出**：3D 协方差矩阵 $\Sigma_{3D}$

1.  将四元数 $q$ 转换为旋转矩阵 $R \in \mathbb{R}^{3 \times 3}$。
2.  构建对角缩放矩阵 $S = \text{diag}(\exp(s))$。
3.  计算 3D 协方差：
    $$ \Sigma_{3D} = R S S^T R^T $$

这一步决定了高斯球在世界空间中的朝向和胖瘦。

### 步骤 2: 投影与 EWA Splatting (Projection)

**输入**：$\mu, \Sigma_{3D}$, 相机外参 $W$, 投影雅可比 $J$
**输出**：2D 屏幕坐标 $\mu_{2D}$, 2D 协方差 $\Sigma_{2D}$

这是最容易出错的数学部分。我们使用 EWA (Elliptical Weighted Average) 算法的近似。

1.  **位置投影**：将中心点 $\mu$ 变换到相机坐标系 $\mu_{cam} = W \cdot \mu$，再投影到屏幕坐标 $\mu_{2D}$。
    *   *Gotcha*: 如果 $\mu_{cam}.z < 0$（在相机背面），必须在这一步剔除该高斯。

2.  **雅可比矩阵 $J$**：这是投影变换的线性化。对于透视投影，投影函数 $\phi(x,y,z) = (f_x \frac{x}{z}, f_y \frac{y}{z})$ 是非线性的。我们在 $\mu_{cam}$ 处计算其雅可比矩阵 $J \in \mathbb{R}^{2 \times 3}$。
    $$
    J = \begin{bmatrix}
    f_x/z & 0 & -f_x \cdot x/z^2 \\
    0 & f_y/z & -f_y \cdot y/z^2
    \end{bmatrix}
    $$
    *(注：这里省略了坐标系转换的细节，实际实现需注意正负号)*

3.  **协方差投影**：
    $$ \Sigma_{2D} = J W_{rot} \Sigma_{3D} W_{rot}^T J^T $$
    其中 $W_{rot}$ 是外参的旋转部分。计算结果是一个 $2 \times 2$ 的矩阵，描述了高斯在屏幕上的形状（椭圆）。

> **工程技巧**：计算出的 $\Sigma_{2D}$ 可能会因为数值误差变得不可逆。通常在对角线加上极小值 $\lambda$（如 $0.3$ 像素单位），既起到 Low-pass filter (抗锯齿) 的作用，又保证数值稳定。

### 步骤 3: 深度排序 (Sorting)

**输入**：所有有效高斯的深度值 $d$
**输出**：高斯索引的排序列表

由于 Alpha Blending 不满足交换律，必须严格按照深度排序。
*   **对于不透明物体**：通常是从前向后 (Front-to-Back) 或从后向前 (Back-to-Front)。
*   **3DGS 标准做法**：从近到远排序（Front-to-Back），这有利于**Early Stopping**（当像素不透明度饱和时停止计算，节省算力）。但在最简 Python 实现中，**从远到近 (Back-to-Front)** 写起来逻辑更简单，直接叠加即可：
    $$ C_{new} = C_{src} \cdot \alpha + C_{dest} \cdot (1 - \alpha) $$

### 步骤 4: 光栅化与色彩合成 (Rasterization)

**输入**：排序后的 $(\mu_{2D}, \Sigma_{2D}, \alpha, c)$, 像素坐标 $x$
**输出**：最终图像 $I$

对于图像上的每一个像素 $x$（最小实现可以用双重循环遍历像素，虽然慢）：

1.  **筛选**：找到所有覆盖该像素的高斯（通常通过计算 Mahalanobis 距离是否小于 3 来判断）。
2.  **计算贡献度**：对于第 $i$ 个高斯，计算其在像素 $x$ 处的强度 $G_i(x)$：
    $$
    \Delta = x - \mu_{2D_i}
    $$
    $$
    G_i(x) = \exp(-\frac{1}{2} \Delta^T \Sigma_{2D_i}^{-1} \Delta)
    $$
3.  **混合 (Alpha Compositing)**：
    令 $\alpha'_i = \alpha_i \cdot G_i(x)$。
    最终颜色 $C$ 为加权和：
    $$ C = \sum_{i \in \mathcal{N}} c_i \alpha'_i \prod_{j=1}^{i-1} (1 - \alpha'_j) $$

    *   $\prod (1-\alpha'_j)$ 被称为**透射率 (Transmittance)** $T_i$。它代表光线穿过前面 $i-1$ 个高斯后剩余的能量
    *   当 $T_i$ 接近 0 时，后面的高斯不仅看不见，其梯度也会消失。

---

## 4. 反向传播与优化 (Optimization Loop)

只要上述步骤都是用 PyTorch 的算子（`torch.matmul`, `torch.exp` 等）编写的，PyTorch 会自动构建计算图。

### 4.1 损失函数

$$ L = (1 - \lambda) \| I_{pred} - I_{GT} \|_1 + \lambda \text{D-SSIM}(I_{pred}, I_{GT}) $$

*   **L1 Loss**：控制整体色彩准确度。
*   **D-SSIM**：结构相似性 Loss，有助于恢复纹理细节，减少平滑伪影。

### 4.2 梯度流向分析

理解梯度流对于调试至关重要：
1.  **像素误差**产生梯度 $\partial L / \partial C$。
2.  梯度通过混合公式传导至 $\alpha'$ (Opacity) 和 $G_i$ (Gaussian intensity)。
3.  $\partial G_i / \partial \Sigma_{2D}$ 告诉我们椭圆应该变大变小还是旋转。
4.  $\partial G_i / \partial \mu_{2D}$ 告诉我们高斯中心应该往哪个方向移动。
5.  最终梯度流回 3D 参数 $q, s, \mu$。

> **陷阱**：如果个高斯的 $\alpha$ 初始化得太小（如 $< 1/255$），它可能永远无法获得足够的梯度来“苏醒”。如果太大，则可能在训练初期占据过多屏幕空间导致局部极小值。

---

## 5. 自适应密度控制 (Adaptive Density Control)

这是 3DGS 的灵魂。仅靠梯度下降只能移动和形变高斯，无法改变高斯数量。为了建模复杂几何，必须动态改变点云拓扑。

在训练循环中，每隔一定步数（如 100 steps），执行以下逻辑：

### 逻辑 A: 什么时候调整？
我们监控**位置梯度**的累积值 $\nabla_{\mu_{avg}}$。
如果一个点的 $\nabla_{\mu_{avg}} > \tau_{pos}$（例如 0.0002），说明这个点“很挣扎”——它试图移动来拟合某些东西，但力不从心。这通常意味着该区域欠拟合。

### 逻辑 B: 怎么调整？
根据尺度 $s$ 决定策略：

1.  **克隆 (Clone)**：
    *   **场景**：梯度大，但尺度 $s$ 很小。
    *   **解释**：这里可能是一个纹理细节丰富的区域，或者是一个细小的几何结构，一个高斯不够用。
    *   **操作**：在原地复制一个一模一样的高斯。

2.  **分裂 (Split)**：
    *   **场景**：梯度大，且尺度 $s$ 很大。
    *   **解释**：这通常是一个原本很大的高斯试图覆盖一个细节区域（Over-reconstruction），导致严重的伪影。
    *   **操作**：将该高斯删除，并在其原位置附近生成 2 个更小的高斯（尺度除以 1.6）。

### 逻辑 C: 剪枝 (Prune)
为了防止场景无限膨胀：
*   移除 $\alpha < \epsilon$（如 0.005）的透明高斯。
*   移除尺度 $s$ 变得极大的高斯（通常是漂浮在相机前的伪影）。
*   定期将 $\alpha$ 重置为低值（Reset Opacity），强制模型剔除那些“混日子”的冗余高斯。

---

## 6. 最小系统的实现路线图

如果你想亲手实现，建议遵循以下迭代步骤：

1.  **v0.1 - 单个高斯投影**：
    *   手动定义一个高斯，设置相机在 z 轴。
    *   可视化 $\Sigma_{2D}$ 对应的椭圆，验证 $q, s$ 改变时椭圆变化是否符合直觉。

2.  **v0.2 - 纯 Python 渲染器**：
    *   实现上述前向过程。
    *   用一个简单的 Loss（比如让高斯移动到图像中心）测试 `loss.backward()` 是否能更新 $\mu$。

3.  **v0.3 - 完整训练 Loop**：
    *   加载一张图片作为 GT。
    *   初始化 100 个随机高斯。
    *   训练它们拟合这张图片（2D 拟合任务，忽略 3D 投影）。

4.  **v0.4 - 3D 场景拟合**：
    *   引入 COLMAP 相机数据。
    *   实现完整的 3D -> 2D 投影。
    *   加入 Clone/Split 逻辑。

---

## 7. 本章小结

实现最小 3DGS 系统的过程，实际上是对 **可微渲染 (Differentiable Rendering)** 思想的一次洗礼。

*   **数据**：不仅是位置，还有各向异性的形状和视角相关的颜色。
*   **渲染**：是基于高斯分布的概率密度累积，而非三角形光栅化。
*   **优化**：不仅是参数值的优化，更是点云密度的自适应优化。

虽然 Python 实现可能每秒只能跑 0.1 帧，但它让你拥有了透视整个算法的“上帝视角”。当我们在后续章节使用 CUDA 加速版本时，你就会明白那些复杂的 Tile 和 Shared Memory 优化到底是在加速上述哪一步骤。

## 8. 常见陷阱 (Gotchas)

1.  **视图矩阵求逆**：COLMAP 的 `WorldToCamera` (w2c) 和渲染器需要的 `CameraToWorld` (c2w) 经常搞反。投影公式 $W$ 通常指 w2c。
2.  **球谐函数系数**：SH 系数需要乘以特定的常数（如 $C_0 \approx 0.282$）才能转为 RGB。如果忘了乘，颜色会非常暗淡。
3.  **学习率调度**：位置 $\mu$ 的学习率需要根据场景的空间尺度进行缩放。如果不根据 bounding box 大小调整，学习率可能过大导致点云爆炸，或过小导致不动。
4.  **负定矩阵**：如果在实现中为了省事直接优化 $\Sigma$ 的 6 个参数，哪怕加了正则项，稍微激进的习率也会让 $\Sigma$ 失去正定性，导致程序崩溃。请务必优化 $q, s$。
