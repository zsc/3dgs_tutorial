# 第 3 章 · 数据与工具链：从多视到可训练场景

> **本章关键词**：COLMAP、SfM、DUSt3R、Glomap、相机模型、坐标系转换、尺度归一化、SH 系数初始化、gsplat 库

## 1. 开篇：数据——优化的“边界条件”

在 3D Gaussian Splatting (3DGS) 的语境下，我们常常听到“训练”这个词。然而，与传统深度学习不同，3DGS 的训练是对**特定场景**的过拟合（Overfitting）。这意味着**数据就是模型本身**的来源。

如果说优化器（Optimizer）是雕刻家，那么输入图像和初始点云就是大理石。如果大理石内部充满了裂纹（运动模糊、噪点）或形状怪异（错误的相机位姿），雕刻家再高明也无法打磨出完美的 3D 场景。

本章将开从“拍摄一段视频”到“开始 `python train.py`”之间那个黑盒子的盖子。我们将涵盖经典的 COLMAP 流程，也会重点介绍 **2024-2025 年涌现的新范式**（如 DUSt3R 和 Glomap），并详细解析如何为 Scaffold-GS、LangSplat 等高级变体准备数据。

---

## 2. 数据采集：给算法“喂”最好的素材

虽然 3DGS 宣称能处理非受控场景（In-the-wild），但在工程实践中，遵循严格的采集协议能让你的重建质量提升一个档次。

### 2.1 采集黄金法则 (The Golden Rules)

1.  **轨迹策略：汇聚 vs. 漫游**
    *   **物体中心 (Object-Centric)**：即使是重建大场景，也尽量围绕兴趣点做螺旋上升或半球形拍摄。
    *   **避免纯旋转 (Pure Rotation)**：这是 SfM 的死穴。如果相机站在原地只转动头部（仅改变视角方向，光心位移 $\mathbf{t} \approx 0$），SfM 无法通过三角测量恢复深度。**必须有平移 (Translation)**。

2.  **相机设置“三不”原则**
    *   **不要自动对焦 (No Auto-Focus)**：焦距 $f$ 的变化会增加内参优化的难度。锁定焦距，使用小光圈以获得大景深。
    *   **不要自动曝光 (No Auto-Exposure)**：3DGS 假设物体表面颜色是固定的（或仅随视角变化）。亮度的剧烈闪烁会被算法强行解释为“高频纹理”或“各向异性颜色”，导致渲染时画面闪烁。
    *   **不要运动模糊 (No Motion Blur)**：模糊的像素不仅会导致 SfM 特征点提取失败，还会让 3DGS 优化出的高斯球变得扁平而巨大，失去几何细节。**快门速度建议高于 1/100s（室外）或 1/60s（室内）。**

3.  **视频 vs. 图像**
    *   **图像**：质量最高，EXIF 信息完整，适合高精度重建。
    *   **视频**：采集方便，但往往伴随压缩伪影（Compression Artifacts）。
    *   **处理视频的 Trick**：不要均匀抽帧。计算每一帧的拉普拉斯方差（Laplacian Variance）作为清晰度评分，优先保留清晰的帧，剔除模糊帧。

### 2.2 2025 视角的动态物体处理
如果你是为了训练 4DGS 或 WorldSplat，采集时需注意：
*   **多机同步**：若是动态场景，单机移动拍摄会导致“时间错位”。必须使用多相机阵列或假设场景动作是周期性的。
*   **静止背景**：确保画面中有足够的静止区域（背景），以便算法能锁定相机位姿。

---

## 3. 几何核心：SfM 与相机模型深度解析

3DGS 并不直接“看”图片，它依赖 **Structure-from-Motion (SfM)** 提供的几何骨架：相机位姿（Extrinsics）、内参（Intrinsics）和稀疏点云（Sparse Point Cloud）。

### 3.1 经典管线：COLMAP 的生与死

COLMAP 是过去十年的行业标准，但它有两个痛点：慢、对弱纹理（白墙、反光）失效。

#### 标准 COLMAP 流程拆解
1.  **Feature Extraction (SIFT)**：在每张图中找特征点。
2.  **Feature Matching**：两两图像找对应点。这里是耗瓶颈，复杂度 $O(N^2)$。
3.  **Mapper (Reconstruction)**：
    *   **增量式 (Incremental)**：选两张最好的图初始化，然后一张张加进去。这是 COLMAP 默认且最稳的模式。
    *   **全局式 (Global)**：一次性解所有位姿。速度快，但不够鲁棒（直到 2024 年 Glomap 的出现）。
4.  **Image Undistortion**：**关键步骤**。原始照片通常有畸变。3DGS 训练通常推荐使用 COLMAP 的 `image_undistorter` 将图片转换为无畸变的针孔模型（Pinhole），并裁剪掉黑边。

### 3.2 2025 新贵：Glomap 与 DUSt3R

随着深度学习介入几何计算，传统的 SfM 正在被革新。

#### **Glomap** (2024)
*   **定位**：COLMAP 的全局优化版替代品。
*   **优势**：在数千张图片的大场景中，速度比 COLMAP 快 5-10 倍，且内存占用更低。适合城市级 3DGS 重建。

#### **DUSt3R** (2024) —— 颠覆者
DUSt3R (Dense Unconstrained Stereo 3D Reconstruction) 不需要内参，也不做传统的特征匹配。它通过 Transformer 直接回归两张图的**稠密 3D 点图 (Pointmap)**。
*   **原理**：$Network(I_1, I_2) \rightarrow (P_1, P_2)$，其中 $P$ 是像素对应的 3D 坐标。
*   **对 3DGS 的意义**：
    1.  **拯救废片**：在白墙、无纹理物体、大视角变化的场景，COLMAP 会挂掉，但 DUSt3R 能输出可用的位姿和稠密点云。
    2.  **免校准**：不需要知道相机焦距，直接丢进去就能算。
    3.  **初始化**：DUSt3R 输出的是**稠密点云**，而非稀疏点云。用 DUSt3R 初始化的 3DGS 往往收敛更快，几何更实。

### 3.3 坐标系变换：令工程师头秃的重灾区

3DGS 涉及三个核心坐标系，混淆它们是 Bug 的主要来源：

1.  **世界坐标系 (World Space)**：场景的绝对坐标。
2.  **相机坐标系 (View Space)**：以相机光心为原点。
3.  **像素/NDC 坐标系 (Screen Space)**：投影后的 2D 平面。

#### ⚠️ 陷阱：COLMAP vs. NeRF vs. OpenGL
*   **COLMAP / OpenCV**：$+Z$ 轴指向相机**前方**，$+Y$ 轴指向**下方**，$+X$ 指向**右方** (Right-Down-Forward)。
*   **NeRF / OpenGL / Blender**：$+Z$ 轴指向相机**后方**（即看向 $-Z$），$+Y$ 轴指向**上方** (Right-Up-Back)。

**数据加载器的标准动作**：
通常我们将 COLMAP 导出的位姿转换为 NeRF 标准（T_nerf = T_colmap * M_convert），并在渲染时保持一致。
$$
\mathbf{M}_{convert} = \begin{bmatrix} 1 & 0 & 0 & 0 \\ 0 & -1 & 0 & 0 \\ 0 & 0 & -1 & 0 \\ 0 & 0 & 0 & 1 \end{bmatrix}
$$
这相当于绕 X 轴旋转 180 度。

---

## 4. 初始化策略：如何播种高斯

有了 SfM 的输出，下一步是构建 3DGS 的初始状态。

### 4.1 为什么点云不仅是“点”？
Vanilla 3DGS 直接将 SfM 的稀疏点云转化为初始高斯。
*   **位置 (Mean, $\mu$)** = 点的 XYZ。
*   **颜色 (Color)** = 点的 RGB $\rightarrow$ 转换为 SH 的 $f_{dc}$ 系数。
    $$ f_{dc} = (RGB - 0.5) / 0.28209 $$
    (这是基于球谐函数 $Y_{0}^{0}$ 的常数推导出的近似)。

### 4.2 协方差的初始化 (The Scale Heuristic)
高斯球的大小决定了它能覆盖多大的空洞。初始化过大，画面糊成一团；过小，会出现针孔般的黑点。

**KNN 初始化法则**：
计算每个点到其最近的 $k$ 个邻居（通常 $k=3$）的平均距离 $d_{avg}$。
$$ \text{Scale}_{init} = \log(d_{avg}) $$
*注意：这里取对数是因为代码中通常会对 Scale 进行 `exp()` 激活。*

### 4.3 进阶初始化 (2025 Trends)
*   **对于天空/远景**：SfM 很难在天空中生成点。如果不处理，天空会出现伪影。**技巧**：在一个巨大的球壳（Far Field Shell）上随机撒点，并将其颜色初始化为蓝色或环境光颜色。
*   **对于 LangSplat**：除了 RGB，还需为每个高斯初始化一个 $D$ 维的语言特征向量（通常使用 CLIP/SAM 特征经过 PCA 降维后的结果）。
*   **Scaffold-GS**：不初始化独立的高斯，而是初始化“体素格点”或“锚点 (Anchors)”，高斯是从锚点中生成的。

---

## 5. 数据格式与工程标准

为了兼容 `gsplat`、`NerfStudio` 等现代库，数据通常被组织成标准格式。

### 5.1 目录结构 (Standard Layout)
```text
/my_scene
  /images          # 原始图片
  /images_4        # 4倍降采样图片 (用于快速调试)
  /sparse
    /0             # COLMAP 二进制文件 (cameras.bin, images.bin, points3D.bin)
  transforms.json  # 关键！NeRF 格式的相机参数
  point_cloud.ply  # 初始点云 (可选，若无则从 COLMAP 读)
```

### 5.2 transforms.json 详解
这是连接 Python 代码与数据的桥梁。
```json
{
  "fl_x": 1200.5,        // 焦距 X
  "fl_y": 1200.5,        // 焦距 Y
  "cx": 800.0,           // 主点 X
  "cy": 600.0,           // 主点 Y
  "w": 1600,             // 宽
  "h": 1200,             // 高
  "frames": [
    {
      "file_path": "images/0001.png",
      "transform_matrix": [ ... ] // 4x4 c2w 矩阵 (OpenGL 坐标系)
    },
    ...
  ]
}
```

### 5.3 尺度归一化 (Scene Normalization) —— 极其重要
优化器（如 Adam）通常在参数值在 $[-1, 1]$ 范围内表现最好。
如果你的场景坐标是 GPS 坐标（数值极大），浮点精度误差和梯度问题会毁了训练。

**标准做法**：
1.  计算所有相机中心和点云的 Bounding Box。
2.  计算场景中心 `center` 和 半径 `radius`（通常取相机分布范围的 1.1 倍）。
3.  应用变换：$P_{new} = (P_{old} - center) / radius$。
4.  将归一化后的场景存入数据加载器，渲染时只需在单位球内采样。

---

## 6. 工具链生态 (2025版)

### 6.1 核心库：gsplat
Inria 官方的 diff-gaussian-rasterization 已经逐渐被 `gsplat` (by NerfStudio team) 取代。
*   **主要特性**：
    *   **Tile-based Rasterization 优化**：更快的排序，更低的显存。
    *   **N-D 属性支持**：不仅支持 RGB，还支持任意维度的特征通道（深度、语义、不确定性），这是做 LangSplat 或 Uncertainty-aware 3DGS 的基础。
    *   **Pose 梯度计算**：支持反向传播到相机位姿，允许在训练中微调相机（Pose Refinement）。

### 6.2 可视化与调试
*   **Viser**：Python 可视化库，支持在浏览器中实时查看 3DGS 训练过程的点云、相机轨迹。
*   **SplatViz / SuperSplat**：基于 WebGL 的轻量级查看器。训练完生成的 `.ply` 或 `.splat` 文件，直接拖进网页就能看，极大地方便了 demo 展示。

---

## 7. 本章小结

*   **数据预处理是第一道防线**：去模糊、去自动曝光、保证重叠率。
*   **SfM 正在进化**：虽然 COLMAP 仍是基石，但面对困难场景，请尝试 DUSt3R。
*   **坐标系与单位**：必须统一坐标系（通常转为 OpenCV 或 OpenGL 标准），并严格执行场景尺度归一化。
*   **初始化决定收敛**：利用 KNN 初始化各向同性高斯，是防止“空洞”和“伪影”的经验法则。

---

## 8. 常见陷阱与错误 (Gotchas)

### 🔴 陷阱 1：透明背景的 PNG 图片
*   **现象**：如果你用抠图软件去掉了背景，留下了透明通道。
*   **后果**：3DGS 会在透明区域看到“随机的颜色”（取决于你读取图片时如何处理 Alpha=0 的像素），导致背景产生大量噪声高斯。
*   **解决**：训练时必须将透明背景处理为**纯色（通常是黑色或白色）**，或者在 Loss 计算时使用 Alpha Mask 忽略背景区域。

### 🔴 陷阱 2：COLMAP 失败的“两张图”诅咒
*   **现象**：COLMAP 输出的点云只有两层平面，或者相机轨迹成了一条直线。
*   **原因**：拍摄时只有纯平移或纯旋转，或者使用了大广角畸变严重的镜头且没有正确设定相机模型。
*   **调试**：在 COLMAP GUI 中手动检查特征匹配连线。如果连线很少，调整 SIFT 阈值或换用 SUPERPOINT/SUPERGLUE 特征提取器。

### 🔴 陷阱 3：显存爆炸 (OOM)
*   **现象**：一启动训练 GPU 就由 100% 显存占用然后崩溃。
*   **原因**：片分辨率太高，或者初始点云数量过多（数百万级）。
*   **解决**：
    1.  训练初期将图片 Resize 到 1K 分辨率以下。
    2.  对初始点云进行**随机下采样**（通常 10万-50万点足够启动）。
    3.  使用 `gsplat` 等内存优化的库。

### 🔴 陷阱 4：颜色灰暗或过饱和
*   **原因**：SH 系数 0 阶分量（DC）没有正确初始化，或者颜色空间转换错误（sRGB vs Linear）。
*   **Rule of Thumb**：3DGS 内部渲染是在**线性空间**进行的。读取图片后应做 `img = img ** 2.2` (近似 Gamma 解码)，计算 Loss 时再做 `img = img ** (1/2.2)`。或者直接在 sRGB 空间算 Loss（官方代码的做法），但需确保 SH 转换逻辑匹配。
