# 第 5 章 · 结构化与可扩展 3DGS：Scaffold-GS 与层次化表达

> **本章摘要**：
> 随着 3DGS 应用场景从简单的物体转向大规模城市和复杂室内环境，原始（Vanilla）3DGS 的“非结构化点云”特性成为了性能与存储的瓶颈。
> 本章将深度解析 **Scaffold-GS** 及其后续变体，探讨如何通过引入 **“锚点（Anchor）- 神经高斯（Neural Gaussian）”** 的层次化结构，实现**存储体积减少 10-20 倍**的同时提升渲染质量。
> 我们还将讨论结构化表示如何解决“视角依赖的几何混叠”问题，并对比 Octree、Hash Grid 等不同空间数据结构在 3DGS 中的应用。

---

## 5.1 痛点分析：Vanilla 3DGS 的“无序之殇”

在深入新方法前，我们需要明确原始 3D Gaussian Splatting 在工程落地中面临的“三大原罪”：

1.  **存储与传输瓶颈**
    *   **现象**：一个高保真的城市场景可能包含 500 万到 1000 万个高斯点。每个点显式存储位置（float32 x3）、旋转（x4）、缩放（x3）、不透明度（x1）和球谐系数（SH, x48 for degree 3）。
    *   **后果**：模型文件动辄 500MB - 2GB。这对于 Web 端加载、移动端应用或云端流式传输都是不可接受的。
    *   **本质**：数据存在极大的**冗余**。相邻的高斯往往具有相似的颜色、纹理趋势和几何朝向，但 Vanilla 3DGS 并没有利用这种局部相关性。

2.  **抗锯齿与多尺度（LOD）缺失**
    *   **现象**：当相机拉远时，原本密集的微小高斯在屏幕上投影小于 1 个像素。
    *   **后果**：画面出现高频噪点（Aliasing）或闪烁，且渲染开销并不会因为物体变远而显著降低（因为主要瓶颈在排序和栅化前的投影计算）。
    *   **本质**：缺乏**层次化（Hierarchical）** 表示。

3.  **视角依赖的伪影**
    *   **现象**：由于高斯是半透明的，优化器常常通过“堆叠”多个高斯来“欺骗”损失函数，以模拟镜面反射（Specular）。当视角稍微偏离训练视角时，这些堆叠结构会暴露，产生“云雾状”伪影。

---

## 5.2 Scaffold-GS 核心原理：锚点与神经高斯

**Scaffold-GS** (CVPR 2024) 提出了一种基于 **锚点（Anchor）** 的混合表示法。它不再直接优化数百万个高斯，而是构建了一个稀疏的脚手架（Scaffold），通过神经网络动态“生长”出高斯。

### 5.2.1 层次化结构图解

我们可以将场景理解为两级结构：

```text
Level 0: 稀疏锚点 (Anchors) - 显式存储
-----------------------------------------------------------
数据量:   约占总高斯数量的 1/10 ~ 1/20
存储内容: [位置 P] [特征 F] [缩放 L] [旋转 Q]
作用:     构场景的骨架，覆盖宏观几何结构

          |  (解码过程: MLP + View Direction)
          V

Level 1: 神经高斯 (Neural Gaussians) - 隐式生成 (On-the-fly)
-----------------------------------------------------------
数据量:   每个锚点生成 K 个高斯 (例如 K=10)
存储内容: 无 (运行时计算，用完即弃或缓存)
特性:     
  1. 位置偏移 (Offset) -> 补全局部几何细节
  2. 属性动态化 -> Opacity/Color 随视角改变
```

### 5.2.2 核心公式：解码与视点自适应

Scaffold-GS 的核心是一个轻量级的 MLP $\mathcal{F}$。对于第 $i$ 个锚点 $A_i$，给定当前相机中心 $C_{cam}$，我们首先计算相对视角方向 $v_i = \frac{C_{cam} - \mu_i}{\|C_{cam} - \mu_i\|}$。

解码过程如下：

$$
\{ \mathcal{G}_{i,j} \}_{j=1}^K = \mathcal{F}\left( f_i, \gamma(v_i), \mu_i, l_i \right)
$$

生成的第 $j$ 个神经高斯 $\mathcal{G}_{i,j}$ 包含属性：
*   **偏移量** $\delta \mu_{i,j}$：$\mu_{i,j} = \mu_i + \delta \mu_{i,j}$
*   **颜色** $c_{i,j}$：替代了显式的 SH 系数
*   **不透明度** $\alpha_{i,j}$
*   **协方差参数**（缩放与旋转的修正）

#### 关键创新：View-Dependent Geometry (VDG)
请注意，输入包含了视角 $v_i$。这意味着**生成的神经高斯的位置和形状是可以随视角变化的！**

> **物理直觉**：
> 在现实世界中，复杂表面（如毛发、半透明材质、强反光水面）在不同角度下看起来几何轮廓是不同的。
> *   **Vanilla 3DGS**：几何固定，仅靠颜色（SH）变化来模拟光影，这在很多时候是不够的。
> *   **Scaffold-GS**：允许高斯微调其位置和形状。例如，在模拟高光移动时，不仅颜色变亮，高斯球本身可以稍微移动或压扁，以更好地捕捉高频反射。

### 5.2.3 训练时的正则化

由于神经高斯是由网络“凭空”生成的，如果不加约束，它们可能会飞到离锚点很远的地方，导致场景混乱。Scaffold-GS 引入了 **体积正则化（Volume Regularization）**：

$$
\mathcal{L}_{vol} = \frac{1}{|A|K} \sum_{i,j} \text{ReLU}\left( \| \delta \mu_{i,j} \|_2 - \lambda \cdot \| l_i \|_2 \right)
$$

*   **含义**：惩罚那些跑出锚点控制范围（$l_i$）太远的子高斯。
*   **效果**：强制每个锚点只负责其局部的纹理和几何，保证了场景的结构化（Locality）。

---

## 5.3 进阶：Octree 与多分辨率策略

除了基于 MLP 的 Scaffold-GS，**Octree-GS** 是另一种常见的结构化思路，它侧重于**渲染效率**和 **Level of Detail (LOD)**。

### 5.3.1 八叉树结构 (Octree)
将 3D 空间递归划分为八个子立方体。每个叶子节点（Leaf Node）存储一组高斯。

*   **空间索引**：通过 Morton Code (Z-order curve) 将 3D 坐标映射为 1D 索引，极大提升内存访问的局部性（Cache coherency）。
*   **视锥剔除（Frustum Culling）**：渲染前，先判断八叉树的大节点是否在视野内。如果不在，直接丢弃该节点下所有成千上万个高斯。这比逐个高斯判断快得多。

### 5.3.2 LOD 渲染策略
结构化 3DGS 可以实现类似游戏引擎的 LOD 机制：

1.  **Level 0 (远景)**：只渲染八叉树粗糙层级的聚合高斯（或者只渲染 Scaffold-GS 的锚点本身）。
2.  **Level 1 (中景)**：展开八叉树，或者让 MLP 解码出部分神经高斯。
3.  **Level 2 (近景)**：完全展开所有细节。

> **Rule of Thumb**：
> 在大规模场景（如无人机航拍城市）中，实现 LOD 是必须的。否则，渲染远处物体时，过多的重叠高斯不仅浪费算力，还会导致严重的**走样（Aliasing）**。

---

## 5.4 结构化方案对比：Scaffold vs. Grid vs. Tri-plane

在 2024-2025 年的文献中，你经常会看到不同的结构化表达。下表是选型指南：

| 特性 | Vanilla 3DGS | Scaffold-GS | Grid/Voxel-GS | Tri-plane / K-Planes |
| :--- | :--- | :--- | :--- | :--- |
| **基本单元** | 独立高斯球 | 稀疏锚点 | 稠密体素网格 | 正平面特征图 |
| **存储效率** | 低 (1x) | **极高 (20x-50x)** | 中 (依赖稀疏性) | **极高 (压缩成图片)** |
| **渲染速度** | 极快 (Native) | 略慢 (需 MLP 解码) | 快 | 中 (需多次采样插值) |
| **几何连续性** | 差 (离散) | **优 (局部连续)** | 优 | 优 (但易过度平滑) |
| **适用场景** | 物体/小场景 | **大规模/复杂反光** | 需物理碰撞检测 | 主要是物体/人脸 |
| **训练显存** | 低 | 中 (MLP 反向传播) | 高 | 低 |

*注：Tri-plane 方法（如 TensoRF 思想的移植）虽然存储极小，但在表达“无界场景”（Unbounded Scenes）时往往不如锚点或八叉树灵活。*

---

## 5.5 常见陷阱与错误 (Gotchas)

在复现或改进 Scaffold-GS 类算法时，以下坑非常容易踩：

### 1. 锚点初始化的“冷启动”问题
*   **陷阱**：直接在空空间中随机撒点，或者网格初始化太稀疏。
*   **现象**：模型无法收敛，或者出现大面积空洞。
*   **原理**MLP 需要依附于正确位置的锚点才能修饰细节。如果锚点位置本身是错的，MLP 很难学出几十厘米甚至几米的位移来修正它。
*   **对策**：
    *   **高质量 SfM**：尽量使用 COLMAP 的稠密点云初始化。
    *   **两阶段训练**：先跑 2000 步 Vanilla 3DGS 得到粗糙高斯分布，然后对其进行体素下采样（Voxel Downsampling），将剩下的中心点作为 Scaffold-GS 的锚点。

### 2. 特征维度与 MLP 宽度的平衡
*   **陷阱**：为了压缩，把锚点特征 $f_i$ 设得很小（如 8 维），或者把 MLP 设得太深（如 4 层）。
*   **现象**：前者导致画面模糊（欠拟合），后者导致 FPS 暴跌且难以训练。
*   **经验值**：
    *   锚点特征维度：32 ~ 64 之间。
    *   MLP 结构：1 ~ 2 层隐藏层，宽度 64。
    *   **Key Insight**：让显式特征（锚点）承担主要信息，MLP 只负责“解压”和“微调”。不要试图把整个场景“背”在 MLP 的权里（那是 NeRF 做的事）。

### 3. 消失的梯度与锚点生长
*   **陷阱**：在训练后期，某些区域细节不足，但并没有生成新的锚点。
*   **调试**：检查锚点生长策略。Scaffold-GS 依赖于**累积梯度**。如果某些区域因为视锥剔除或其他原因没有梯度回传，锚点就不会分裂。
*   **技巧**：定期（每 1000 iter）统计每个锚点的覆盖范围和视图空间梯度。对于梯度大且覆盖范围也大的锚点，强制分裂。

### 4. 显存爆炸 (OOM)
*   **陷阱**：虽然存储变小了，但在训练时，PyTorch 需要保存 MLP 的计算图用于反向传播。如果你一次性解码几百万个锚点，24G 显存瞬间爆炸。
*   **对策**：
    *   **Stochastic Decoding**：训练时不要解码所有锚点。只解码视锥内（Frustum）的，或者随机采样部分锚点进行训练。
    *   **Chunking**：将图像分块渲染（Tile-based），虽然 gsplat 已经是 tile-based，但在 MLP 解码阶也需要分批次进行。

---

## 5.6 本章小结

1.  **结构化的必要性**：为了处理大规模场景和降低存储，必须从“汤（Soup）”式的高斯转变为有组织的结构。
2.  **Scaffold-GS 范式**：通过 **Anchor + MLP** 实现了**显式索引与隐式生成**的结合。
3.  **View-Adaptive 能力**：这是结构化 3DGS 超越 Vanilla 的关键——不仅颜色随视角变，**几何形态**也可以随视角微调，极大地增强了对高光和复杂材质的表现力。
4.  **工程权衡**：我们用少量的计算开销（MLP 推理），换取了巨大的存储优势和更好的图像质量。

---

[< 上一章：从零实现一个最小 3DGS 系统](chapter4.md) | [目录](index.md) | [下一章：动态场景与 4D Gaussian Splatting >](chapter6.md)
