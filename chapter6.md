# 第 6 章 · 动态场景与 4D Gaussian Splatting

> **本章摘要**：
> 现实世界很少是完全静止的。本章将打破 3DGS 的“静态假设”，深入探讨如何在时间维度上扩展高斯表达。
> 
> 我们将首先剖析动态场景重建中的核心矛盾：**拟合能力 vs. 时间一致性**。随后，我们将详细拆解解决该问题的三大数学范式：**拉格朗日视角（基于形变）**、**欧拉/时空视角（基于 4D 原语）** 以及 **混合视角（静态/动态解耦）**。
> 
> 特别地，本章将重点介绍 **HexPlane** 加速结构、**4D 旋转切片** 原理，以及 2025 年前后的前沿工作——如 **WorldSplat** 如何结合生成模型解决自动驾驶场景中的“物体消失”与背景修复问题。
>
> **学习目标**：
> 1. 理解 3DGS 处理动态场景时的“幽灵影”与“模糊”成因。
> 2. 掌握 **形变场 (Deformation Field)** 与 **规范空间 (Canonical Space)** 的设计模式。
> 3. 深入理解 **原生 4D Gaussian** 的数学表达，特别是协方差矩阵的时间切片（Slicing）推导。
> 4. 学会构建 **静态/动态双流系统**，并在自动驾驶场景中处理刚体运动。
> 5. 了解结合 Diffusion 模型的生成式背景修复流程。

---

## 6.1 静态假设的破裂：从“拍照”到“录像”

在第 2 章中，我们定义了 3DGS 的核心是一个从位置 $x$ 到颜色 $c$ 和密度 $\alpha$ 的映射。如果场景是静止的，这个映射是固定的。然而，一旦引入时间 $t$，我们面临着全新的挑战。

### 6.1.1 幽灵影 (Ghosting) 与 模糊 (Blurring)
如果我们强行用一组静态的高斯球去拟合一段包含移动物体的视频，优化器会陷入两难：
1.  **幽灵影 (Ghosting)**：如果物体移动很快且帧率较低，优化器会在物体轨迹的每一个位置成一组半透明的高斯。看起来就像物体留下了长长的残影。
2.  **时间平均模糊 (Temporal Blurring)**：如果物体移动较慢或帧率很高，优化器会试图“平均”每一帧的颜色。结果是生成一个巨大的、极其膨胀的高斯球，笼罩整个运动轨迹，导致细节完全丢失。

### 6.1.2 核心矛盾：显存 vs. 连续性
最暴力的解法是：每一帧训练一个独立的 3DGS 模型。
- **优点**：画质极高，完全拟合。
- **缺点**：显存爆炸（每秒 30 个模型），且帧与帧之间毫无关联（时间不一致），播放时会产生剧烈的闪烁（Flickering）。

因此，动态 3DGS 的核心任务是：**寻找一种紧凑的表达，既能复用大部分信息（静态背景），又能平滑地描述随时间变化的部分。**

---

## 6.2 范式一：拉格朗日视角 —— 形变场 (Deformation Fields)

这种方法继承自 NeRF 时代的 D-NeRF。其核心思想是：**高斯本身不随时间产生与亡，它们只是在空间中“流动”。**

### 6.2.1 规范空间与观测空间
我们定义两个空间：
1.  **规范空间 (Canonical Space)**：$t=0$ 或一个抽象的参考时刻。这里存储着高斯的“原始状态” $\mu_{can}, \Sigma_{can}, c_{can}$。
2.  **观测空间 (Observation/Deformed Space)**：$t=t_i$ 时刻，我们实际看到的场景。

我们需要一个函数 $\Phi$，将高斯从规范空间“推”到观测空间：
$$
\begin{aligned}
(\Delta \mu, \Delta r, \Delta s) &= \Phi(x_{can}, t) \\
\mu_{obs} &= \mu_{can} + \Delta \mu \\
r_{obs} &= r_{can} + \Delta r \\
s_{obs} &= s_{can} + \Delta s
\end{aligned}
$$
其中 $r$ 是旋转（四元数），$s$ 是缩放。

### 6.2.2 加速核心：HexPlane / K-Planes
早期的 $\Phi$ 是一个巨大的 MLP，速度很慢。为了保持 3DGS 的实时性，**HexPlane (六平面)** 或 **K-Planes** 结构成为 2024 年以后的标准配置。

我们不直接用 MLP 处理 $(x,y,z,t)$，而是将 4D 时空分解为 6 个 2D 面：
- 空间平面：$XY, XZ, YZ$
- 时空平面：$XT, YT, ZT$

对于一个点 $q=(x,y,z,t)$，其特征向量 $F$ 计算如下：
$$
F(q) = \prod_{plane \in \{xy, \dots, zt\}} \text{Interp}(M_{plane}, \text{proj}_{plane}(q))
$$
最后只用一个极小的 MLP 将特征 $F(q)$ 解码为位移 $\Delta \mu$。

> **Rule of Thumb (HexPlane 设计)**：
> 在实践中，空间平面 ($XY, \dots$) 分辨率通常较高（如 $2048^2$），捕捉细节；而时空平面 ($XT, \dots$) 分辨率较低（如 $256 \times T$），捕捉运动。这种**各向异性分辨率**设计是平衡显存与质量的关键。

### 6.2.3 局限性
形变场非常适合**非刚性形变**（如飘动的旗帜、面部表情）。但对于**拓扑结构变化**（如倒水、切开蛋糕）处理很差，因为很难用连续函数模拟“分裂”。

---

## 6.3 范式二：欧拉/时空视角 —— 原生 4D Gaussian Splatting

这是 2024-2025 年的一个重要理论突破（代表作：Spacetime Gaussians, 4D-GS）。
思路：**不要把时间当作外部变量，直接把高斯定义在 4D 空间中。**

### 6.3.1 4D 椭球定义
一个 4D 高斯由 4D 均值 $\mu_{4D} = (\mu_x, \mu_y, \mu_z, \mu_t)$ 和 $4 \times 4$ 协方差矩阵 $\Sigma_{4D}$ 定义。
$$
\Sigma_{4D} = R_{4D} S_{4D} S_{4D}^T R_{4D}^T
$$
这里 $R_{4D}$ 是 4D 旋转矩阵，$S_{4D}$ 是对角缩放矩阵。

### 6.3.2 渲染：时间切片 (Slicing)
当我们渲染 $t_{now}$ 时刻的图像时，本质上是用超平面 $t = t_{now}$ 去“切”这个 4D 椭球。
根据高斯分布的边缘化与条件化性质，切片后的结果**仍然是一个 3D 高斯**。

假设我们将 $\mu$ 和 $\Sigma$ 分块：
$$
\mu_{4D} = \begin{bmatrix} \mu_{xyz} \\ \mu_t \end{bmatrix}, \quad
\Sigma_{4D} = \begin{bmatrix} A & B \\ B^T & D \end{bmatrix}
$$
其中 $A$ 是 $3 \times 3$ 空间协方差，$D$ 是 $1 \times 1$ 时间方差。
在 $t = t_{now}$ 处的切片 3D 高斯参数为：
$$
\begin{aligned}
\mu'_{xyz} &= \mu_{xyz} + B D^{-1} (t_{now} - \mu_t) \\
\Sigma'_{xyz} &= A - B D^{-1} B^T
\end{aligned}
$$
**公式直觉**：
- 新的中心 $\mu'$ 会根据时间差 $(t_{now} - \mu_t)$ 和时空相关性 $B$ 进行线性偏移。这就是运动的来源！
- 新的协方差 $\Sigma'$ 会比原始空间协方差 $A$ 小（减去了一项），这体现了切片操作确定了时间，减少了不确定性。

### 6.3.3 4DGS 的优势
- **解析解**：不需要神经网络去预测位移，运动完全由 $R_{4D}$ 矩阵编码。
- **极其高效**：推理时只需做矩阵运算，不用跑 MLP。
- **能处理出现/消失**：通过 $Opacity(t)$ 函数，或者简单地将 $\mu_t$ 移出渲染时间范围，即可实现物体的自然生灭。

---

## 6.4 范式三：工程解耦 —— 静态背景 + 动态物体

在自动驾驶和大规模场景重建（如 WorldSplat, Street Gaussians）中，纯数学方法往往不如**结构化解耦**有效。

### 6.4.1 双流架构 (Dual-Stream Architecture)
我们将场景强制拆解为两组高斯：
$$
I = \text{Blend}(I_{static}, I_{dynamic}, \text{Mask})
$$

1.  **Static Gaussians**：
    *   参数：$\mu, \Sigma, c$ (常数)。
    *   约束：只能优化位置和颜色，不能随时间动。
2.  **Dynamic Gaussians**：
    *   参数：可以是 Deformable GS，也可以是附着在 Object Coordinates 上的刚体 GS。
    *   约束：通常绑定了 bounding box。

### 6.4.2 刚体运动与 Object-Centric Modeling
对于汽车，我们不需要学习每个顶点的形变，只需要学习车的 **Pose**。
$$
\mu_{world}(t) = R_{car}(t) \cdot \mu_{local} + T_{car}(t)
$$
- 训练时，我们将点云变换到车的局部坐标系初始化高斯。
- 每一帧只优化 $R_{car}(t)$ 和 $T_{car}(t)$（6个参数），而不是优化几万个高斯的位移。这极大地稳定了训练。

### 6.4.3 常见伪影处理：天空与阴影
*   **天空**：通常设为超远距离的大高斯球，或者使用 Environment Map 建模。
*   **动态阴影**：这是个难点。阴影是投射在静态路面上的动态纹理。
    *   *技巧*：允许静态路面高斯的颜色 $c$ 随时间微小变化（Spherical Harmonics 系数随 $t$ 变化），或者专门训练一个 "Shadow Field"。

---

## 6.5 2025 前沿：WorldSplat 与生成式修复

到了 2025 年，研究不再满足于“复现录像”，而是要求“构建可编辑的世界”。**WorldSplat** 是处理**多遍历 (Multi-traversal)** 数据的代表。

### 6.5.1 场景：消失的红车
假设采集车第一天经过路口，路边停着一辆红车；第二天经过，红车走了。
- 如果直接合并数据：红车会变成半透明幽灵。
- 如果简单删除红车：红车原来的位置会留下一个“黑洞”，因为相机没拍到过红车背后的墙。

### 6.5.2 Pipeline：检测-删除-生成
WorldSplat 提出了一套闭环流程：
1.  **4D 标注/聚类**：利用 4DGS 的运动特性或语义特征（LangSplat），自动识别出“红车”是瞬态物体。
2.  **擦除**：从高斯列表中硬除属于红车的高斯。
3.  **生成式补全 (Inpainting)**：
    *   将当前视角渲染出带有“空洞”的 RGB 图像。
    *   使用 **ControlNet / Stable Diffusion** 对空洞进行 Inpainting，生成合理的背景（如延续路边的围墙纹理）。
    *   将生成的像素作为新的“伪真值 (Pseudo-GT)”。
4.  **重训练**：在空洞区域初始化新的 Static Gaussians，并利用 Pseudo-GT 进行训练。

这一流程标志着 3DGS 从 **Discriminative（判别式/拟合）** 走向 **Generative（生成式）** 的融合。

---

## 6.6 本章小结

| 维度 | 形变场 (Deformation) | 4D 高斯 (Spacetime) | 静态/动态解耦 (Decoupling) |
| :--- | :--- | :--- | :--- |
| **数学核心** | $x(t) = x_0 + MLP(t)$ | 4D 椭球切片 | $I = I_s + I_d$ |
| **优势** | 适合非刚性形变（人脸、衣服） | 数学优雅，推理极快 | 适合自动驾驶、刚体控制 |
| **劣势** | 训练慢，无法处理拓扑变化 | 实现复杂，显存占用略高 | 需要 Mask 或 BBox 先验 |
| **典型应用** | 虚拟人、短视频特效 | 通用动态场景 | 自动驾驶仿真、SLAM |

**关键公式回顾**：
*   **HexPlane 特征**：$F = \text{interp}(XY) \cdot \text{interp}(XT) \cdots$
*   **4D切片均值**：$\mu' = \mu_{xyz} + B D^{-1} (t - \mu_t)$
*   **场景流损失**：$\mathcal{L}_{flow} = \| \text{Proj}(\mu_{t+1}) - \text{Proj}(\mu_t) - \text{OpticalFlow} \|$

---

## 6.7 常见陷阱与错误 (Gotchas)

### 1. “浮游生物” (Floaters) 爆炸
*   **现象**：动态场景训练中，相机近处出现大量细碎的、杂乱的高斯，像飞舞的灰尘。
*   **原因**：动态模型为了解释视频中的高频噪声或无法拟合的区域，在相机前方生成了瞬态高斯。
*   **对策**：
    *   引入 **Sparsity Loss**（稀疏性损失）：惩罚透明度低的高斯数量。
    *   引入 **Smoothness Loss**（平滑性损失）：惩罚相邻时间步之间加速度过大的高斯。

### 2. 时间过拟合 (Temporal Overfitting)
*   **现象**：训练集看着完美，测试集（如插帧 $t=0.5$）画面崩坏。
*   **原因**：形变网络记住了每个整数帧的状态，而在非整数帧位置行为不可控。
*   **对策**：
    *   降低形变网络（如 HexPlane）的时间分辨率。
    *   **关键**：随机采样非整数时间 $t$ 进行训练（如果数据允许），或者对 $t$ 加微小抖动（Jitter）。

### 3. SLAM 中的动态物体干扰
*   **现象**：在跑 GS-SLAM 时，如果有人走过，整个地图的轨迹都歪了。
*   **原因**：SLAM 前端把移动的人当成了特征点，误以为是相机在动。
*   **对策**：必须先做 **Motion Segmentation**。凡是 Mask 内的像素，不参与 Camera Pose 的优化，仅参与地图更新（或者直接丢弃）。

### 4. 4D 旋转矩阵的陷阱
*   **问题**：在实现 4DGS 时，如果直接优化 $4 \times 4$ 矩阵，很容易导致协方差非正定。
*   **对策**：始终构造 $R$ (旋转) 和 $S$ (缩放) 分别优化。对于 4D 旋转，建议分解为 **3D 空间旋转** 和 **6 个双平面旋转 (Bi-plane rotations)** 的组合，以保证数值稳定性。

---

[< 第 5 章：结构化与可扩展 3DGS](chapter5.md) | [目录](index.md) | [第 7 章：3DGS + SLAM >](chapter7.md)
