# 第 1 章 · 3DGS 与三维重建概览 —— 从 NeRF 到 Splat 的大图景

## 1.1 开篇：图形学的“不可能三角”被打破

在计算机图形学和三维视觉的长期探索中，我们始终在一个“不可能三角”中做权衡：
1.  **照片级真实感 (Photorealism)**：能否以假乱真？
2.  **实时渲染速度 (Real-time Rendering)**：能否达到 30fps 甚至 60fps+？
3.  **训练/构建效率 (Training Efficiency)**：重建一个场景需要几分钟还是几天？

**传统图形学**（基于 Mesh 和纹理）做到了实时，但难以自动处理复杂的真实世界光影；**NeRF (Neural Radiance Fields)** 在 2020 年横空出世，解决了真实感问题，但其隐式表达（Implicit Representation）让实时渲和快速训练成为了噩梦。

**2023 年，3D Gaussian Splatting (3DGS) 的出现，被视为继 NeRF 之后的第二次革命。**
它不是对 NeRF 的修补，而是从根本上改变了底层表达——放弃了“黑盒”神经网络，回归了“白盒”显式几何。它奇迹般地同时满足了上述三点：
- **画质**：SOTA (State-of-the-Art) 级别，甚至在细节纹理上优于 NeRF。
- **速度**：在消费级 GPU 上轻松达到 100fps+ (1080p)。
- **效率**：训练时间从 NeRF 的“小时级”缩短到“分钟级”。

本章将带你鸟瞰这一技术的全貌，理解它是如何将 90 年代的复古技术与现代可微编程结合，并在 2025 年演化出一个庞大的技术生态的。

---

## 1.2 三维重建简史：从几何到辐射场，再回归几何

要理解 3DGS 的位置，我们需要快速回顾一下历史的钟摆是如何摆动的。

### 1. 显式几何时代 (SfM & MVS)
*代表作：COLMAP, OpenMVS*
- **逻辑**：通过特征点匹配计算相机位姿，三角化生成点云，然后重建网格 (Mesh)。
- **痛点**：对于弱纹理区域（白墙）、反光物体（玻璃）、细小结构（头发、电线）几乎无能为力。重建的 Mesh 往往充满破洞或噪声。

### 2. 隐式场时代 (NeRF & Volumetric Rendering)
*代表作：NeRF, Instant-NGP, Mip-NeRF*
- **逻辑**：**“不要问物体表面在哪里，要问光线经过这里会发生什么。”**
    - 世界被建模为一个连续的函数 $F(x, y, z, \theta, \phi) \to (RGB, \sigma)$。
    - 使用 MLP（多层感知机）来拟合这个函数。
    - **体渲染 (Volume Rendering)**：沿着光线采样数百个点，积分颜色。
- **痛点**：
    - **计算量爆炸**：渲染一个像素 = 跑几百次神经网络。
    - **修改困难**：场景被压缩在神经网络权重里，无法像编辑 Mesh 一样“删掉一把椅子”。

### 3. 显式辐射场回归 (3DGS)
*代表作：3D Gaussian Splatting (SIGGRAPH 2023)*
- **逻辑**：**“用带颜色的模糊毛球（高斯）填满空间，然后把它们拍扁在屏幕上。”**
    - **回归显式**：数据不再是神经网络权重，而是数百万个具体的、离散的“高斯球”。
    - **保留辐射场特性**：每个高斯球带有透明度 ($\alpha$) 和视点相关颜色 (SH)，依然使用 Alpha Blending 模拟光线穿过雾气的效果，完美保留了 NeRF 的半透明和反光能力。

---

## 1.3 核心直觉：什么是 "Gaussian Splatting"？

### 1. 场景的基本单元：3D 高斯 (The 3D Gaussian)
不同于点云中的“点”（只有一个坐标），3D 高斯是一个**有体积、有方向的椭球体**。
想象一下，你手里有一团软泥：
- **位置 ($\mu$)**：决定它在哪里。
- **协方差 ($\Sigma$)**：决定你是把它搓成一个圆球，还是压扁成飞盘（模拟墙面），或者拉长成雪茄（模拟电线）。**各向异性 (Anisotropy)** 是 3DGS 能够用少量点拟合精细几何的关键。
- **不透明度 ($\alpha$)**：决定它有多实。
- **球谐系数 (SH)**：决定它的颜色随观看角度如何变化（模拟金属光泽或丝绸质感）。

### 2. 渲染机制：Splatting (抛雪球)
NeRF 是“**主动去查**”：光线射出去，问空间里的点“你是谁”。
3DGS 是“**被动接收**”：高斯球把自己“**投影**”到屏幕上。

这个过程被称为 **Rasterization (光栅化)**，其流水线如下：
1.  **视锥剔除 (Culling)**：把相机背后的、看不见的高斯球扔掉。
2.  **投影 (Projection)**：把 3D 椭球投影到 2D 屏幕平面，变成 2D 椭圆。
3.  **排序 (Sorting)**：**这是最关键的一步**。将所有重叠在某个像素上的高斯球，按照深度（Z-buffer）从远到近排序。得益于 GPU 的 Radix Sort，这步极快。
4.  **混合 (Alpha Blending)**：从前向后（或从后向前）累加颜色。

### 3. 进化的关键：自适应密度控制 (Adaptive Density Control)
3DGS 最迷人的地方不在于渲染，而在于**训练**。
除了优化位置和颜色，3DGS 还会**自动改变高斯球的数量**（这是 NeRF 做不到的）：
- **克隆 (Clone)**：如果一个高斯球太小，覆盖不住几何体（Under-reconstruction），就把它复制一份，填补空隙。
- **分裂 (Split)**：如果一个高斯球太大，方差过高（Over-reconstruction），说明它试图用一个大球拟合复杂的细节，那就把它切成两个小球。
- **剪枝 (Prune)**：如果一个高斯球变得完全透明 ($\alpha \approx 0$) 或大得离谱，直接删除。

> **Rule of Thumb**: 这种“分裂与克隆”机制模拟了生物细胞的繁衍。初始时只有稀疏的随机点云，随着训练进行，高斯球在细节丰富的地方（如树叶、栏杆）疯狂分裂，在平坦区域（如墙壁）保持大而稀疏。这是一种**自动的资源分配**。

---

## 1.4 深度对比：NeRF vs. 3DGS 的计算范式差异

对于工程师而言，理解两者的**硬件瓶颈**至关重要。

| 维度 | NeRF (隐式/体渲染) | 3DGS (显式/Splatting) |
| :--- | :--- | :--- |
| **计算模式** | **Ray Marching** (光线步进) | **Rasterization** (光栅化) |
| **核心操作** | MLP 推理 (矩阵乘法) | 排序 (Sort) + Alpha Blend |
| **硬件瓶颈** | **Compute Bound** (算力受限) | **Memory Bandwidth Bound** (显存带宽受限) |
| **显存占用** | 低 (MB级别，仅存权重) | 高 (GB级别，存数百万个高斯属性) |
| **空间采样** | 采样整个光线路径（含空区域） | 仅处理有高斯存在的区域 (Skip Empty Space) |
| **梯度反传** | 极慢 (需反向穿过数百次采样) | 极快 (仅反传给参与贡献的高斯) |
| **可编辑性** | 几乎为零 (Black Box) | 较好 (可以直接删除/移动高斯) |

**为什么 3DGS 更快？**
1.  **跳过空空间**：NeRF 即使有 Occupancy Grid 加速，依然需要在光线上做采样尝试。3DGS 直接把物体画在屏幕上，完全不计算空的地方。
2.  **GPU 友好**：排序和光栅化是 GPU 诞生三十年来优化得最彻底的操作。

---

## 1.5 2025 年技术图景：从 Demo 到大规模应用

3DGS 作为一个“基础表示层”，在 2024-2025 年间迅速分化出了多个垂直领域的 SOTA 方案。以下是我们课程将重点覆盖的前沿方向：

### 1. 结构化与压缩：驯服显存怪兽
*代表作：Scaffold-GS, Mini-Splatting*
原始 3DGS 的文件体积巨大（一个场景 500MB+），且存在大量冗余。
- **Scaffold-GS** 提出利用**锚点 (Anchor)** 来生成局部高斯，利用神经网络预测属性，大大减少了参数量，并利用视锥体感知解决了多尺度（Level-of-Detail）问题。
- **2025 趋势**：结合矢量量化 (VQ) 和哈希编码，将 3DGS 压缩至 JPG 级别的体积，以便在移动端流式传输。

### 2. 4D 动态世界：打破静态假设
*代表作：4D-GS, Spacetime-GS, WorldSplat*
如何重建跳舞的人或行驶的汽车？
- 早期方法试图让每个高斯动起来 $(x,y,z,t)$。
- **WorldSplat (2025)**：针对自动驾驶场景，不再只是简单的插值，而是结合生成模型，解决动态物体遮挡后的背景修复问题，并能在不同光照/天气下生成连贯的 4D 场景。

### 3. SLAM 与 机器人：从“看”到“动”
*代表作：GS-SLAM, SplaTAM, RTG-SLAM*
传统的 SLAM 输出稀疏点云，机器人看不懂它是“墙”还是“草”。
- **GS-SLAM**：首次实现 RGB-D 稠密建图。
- **RTG-SLAM (2025)**：重点解决**实时性**和**动态物体干扰**。它能够在嵌入式 GPU (Jetson) 上运行，并具备“长期记忆”，不会因为相机快速晃动而把地图搞丢。

### 4. 语义与语言场：与大模型对话
*代表作：LangSplat, LangSplat v2, ConceptGraphs*
我们不仅希望看到颜色，还希望知道“哪部分是椅子”。
- **LangSplat**：将 CLIP 语言特征压缩到高斯中。
- **LangSplat v2 (2025)**：解决了高维特征渲染慢的问题。通过**字典学习 (Dictionary Learning)**，将 512 维的 CLIP 特征压缩为稀疏系数，实现了 >450 FPS 的语义查询速度。你可以直接问：“把所有的红苹果变成绿色的”，系统能毫秒级响应。

### 5. 生成式 3D：AIGC 的新载体
*代表作：DreamGaussian, DiffusionGS, AnySplat*
- **DreamGaussian**：利用 3DGS 的快速初始化能力，将 Text-to-3D 的时间从几小时缩短到 2 分钟。
- **DiffusionGS**：不再依靠 SDS 蒸馏，而是直接训练一个输出 3DGS 参数的 Diffusion Model。
- **AnySplat**：一种前馈 (Feed-forward) 网络。给它几张照片，它直接吐出 3DGS 场景，无需训练优化。这对于瞬时三维重建意义重大。

---

## 1.6 本章小结

1.  **历史地位**：3DGS 终结了“网格光栅化”与“神经体渲染”的二元对立，融合了**显式几何的效率**与**体渲染的可微性**。
2.  **核心机制**：各向异性 3D 高斯球 + 投影 + 排序 + Alpha 混合。
3.  **优化魔法**：自适应密度控制（分裂/克隆）是 3DGS 能够自动拟合杂几何的根本原因。
4.  **工程本质**：从 Compute-bound 转向 Memory-bound，对显存带宽要求高，对张量算力要求相对较低。
5.  **2025 展望**：技术栈已从单一的重建算法演变为包含**压缩、动态、语义、生成**的全方位 3D 数据格式标准。

---

## 1.7 常见陷阱与错误 (Gotchas)

在开启学习之旅前，请务必建立以下正确认知，以防掉坑：

*   **陷阱 1：以为 3DGS 是“网格”**
    *   *现象*：试图把 3DGS 导入 Unity/UE 做物理碰撞（Collision）。
    *   *真相*：3DGS 是一堆“云雾”，没有确定的表面。虽然视觉上看起来是实体的，但物理引擎会直接穿过去。你需要额外的算法（如 Marching Cubes）从高斯中提取 Mesh，或者使用基于粒子的物理模拟。
*   **陷阱 2：忽视初始化**
    *   *现象*：直接随机初始化高斯位置，训练结果一团糟。
    *   *真相*：3DGS 是非凸优化，极其依赖初始点云（通常来自 COLMAP）。如果 SfM 失败，3DGS 必败。虽然 AnySplat 等新方法试图解决此问题，但经典管线中 SfM 仍是地基。
*   **陷阱 3：显存爆炸**
    *   *现象*：在 8GB 显存的显卡上跑大场景，直接 OOM (Out of Memory)。
    *   *真相*：高斯数量增长极快。如果不加控制（正则化），它会为了拟合噪点生成数百万个微小高斯。学会调节 `densification_interval` 和 `opacity_reset_interval` 是工程必修课。
*   **陷阱 4：视角依赖伪影 (Floater)**
    *   *现象*：从训练视角看很完美，稍微转一下相机，发现空中飘着很多奇怪的色块。
    *   *真相*：这是过拟合的表现。高斯球为了强行解释某个视角的像素，在相机镜头前生成了“贴图”。这在 Scaffold-GS 等结构化方法中得到了缓解。

下一章，我们将放下这些高大上的概念，拿起数学手术刀，剖析那个著名的**3D到2D协方差投影公式**——那是整个 3DGS 大厦的基石
